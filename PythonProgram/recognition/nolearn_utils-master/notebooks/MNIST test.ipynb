{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 670\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from lasagne.layers import InputLayer, DenseLayer, DropoutLayer\n",
    "from lasagne.layers.dnn import Conv2DDNNLayer, MaxPool2DDNNLayer\n",
    "from lasagne import nonlinearities\n",
    "from lasagne import objectives\n",
    "from lasagne import updates\n",
    "\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from nolearn.lasagne.handlers import SaveWeights, PrintLayerInfo\n",
    "from nolearn.lasagne.util import get_conv_infos\n",
    "\n",
    "from nolearn_utils.iterators import (\n",
    "    BufferedBatchIteratorMixin,\n",
    "    ReadImageBatchIteratorMixin,\n",
    "    ShuffleBatchIteratorMixin,\n",
    "    LCNBatchIteratorMixin,\n",
    "    RandomFlipBatchIteratorMixin,\n",
    "    EqualizeAdaptHistBatchIteratorMixin,\n",
    "    AffineTransformBatchIteratorMixin,\n",
    "    make_iterator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_size = 28\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "X = mnist.data.reshape(-1, image_size, image_size)\n",
    "y = mnist.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 96\n",
    "n_classes = 10\n",
    "\n",
    "train_iterator_mixins = [\n",
    "    ShuffleBatchIteratorMixin,\n",
    "    RandomFlipBatchIteratorMixin,\n",
    "    AffineTransformBatchIteratorMixin,\n",
    "    EqualizeAdaptHistBatchIteratorMixin,\n",
    "    BufferedBatchIteratorMixin,\n",
    "]\n",
    "TrainIterator = make_iterator('TrainIterator', train_iterator_mixins)\n",
    "\n",
    "test_iterator_mixins = [\n",
    "    EqualizeAdaptHistBatchIteratorMixin,\n",
    "    BufferedBatchIteratorMixin,\n",
    "]\n",
    "TestIterator = make_iterator('TestIterator', test_iterator_mixins)\n",
    "\n",
    "train_iterator_kwargs = {\n",
    "    'buffer_size': 5,\n",
    "    'batch_size': batch_size,\n",
    "    'flip_horizontal_p': 0.5,\n",
    "    'flip_vertical_p': 0.5,\n",
    "    'affine_p': 0.5,\n",
    "    'affine_scale_choices': np.linspace(0.75, 1.25, 5),\n",
    "    'affine_translation_choices': np.arange(-24, 24, 4),\n",
    "    'affine_rotation_choices': np.arange(0, 360, 36),\n",
    "    'eqadapthist_ntiles_x': 16,\n",
    "    'eqadapthist_ntiles_y': 16,\n",
    "}\n",
    "train_iterator = TrainIterator(**train_iterator_kwargs)\n",
    "\n",
    "test_iterator_kwargs = {\n",
    "    'buffer_size': 5,\n",
    "    'batch_size': batch_size,\n",
    "    'eqadapthist_ntiles_x': 16,\n",
    "    'eqadapthist_ntiles_y': 16,\n",
    "}\n",
    "test_iterator = TestIterator(**test_iterator_kwargs)\n",
    "\n",
    "net = NeuralNet(\n",
    "    layers=[\n",
    "        ('in', InputLayer),\n",
    "        ('l1c1', Conv2DDNNLayer),\n",
    "        ('l1c2', Conv2DDNNLayer),\n",
    "        ('l1p', MaxPool2DDNNLayer),\n",
    "\n",
    "        ('l7', DenseLayer),\n",
    "        ('l7drop', DropoutLayer),\n",
    "\n",
    "        ('out', DenseLayer),\n",
    "    ],\n",
    "\n",
    "    in_shape=(None, 1, image_size, image_size),\n",
    "\n",
    "    l1c1_num_filters=32, l1c1_filter_size=(5, 5), l1c1_border_mode='same',\n",
    "    l1c2_num_filters=16, l1c2_filter_size=(5, 5), l1c2_border_mode='same',\n",
    "    l1p_pool_size=(3, 3),\n",
    "    l1p_stride=2,\n",
    "\n",
    "    l7_num_units=128,\n",
    "    l7drop_p=0.5,\n",
    "\n",
    "    out_num_units=n_classes,\n",
    "    out_nonlinearity=nonlinearities.softmax,\n",
    "\n",
    "    regression=False,\n",
    "    objective_loss_function=objectives.categorical_crossentropy,\n",
    "\n",
    "    update=updates.rmsprop,\n",
    "    update_learning_rate=1e-3,\n",
    "\n",
    "    eval_size=0.1,\n",
    "    batch_iterator_train=train_iterator,\n",
    "    batch_iterator_test=test_iterator,\n",
    "\n",
    "    verbose=10,\n",
    "    max_epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felixlau/devel/lasagne/lasagne/init.py:86: UserWarning: The uniform initializer no longer uses Glorot et al.'s approach to determine the bounds, but defaults to the range (-0.01, 0.01) instead. Please use the new GlorotUniform initializer to get the old behavior. GlorotUniform is now the default for all layers.\n",
      "  warnings.warn(\"The uniform initializer no longer uses Glorot et al.'s \"\n",
      "/home/felixlau/devel/nolearn/nolearn/lasagne/base.py:275: UserWarning: lasagne.objectives.Objective is deprecated and will be removed for the first release of Lasagne. For alternatives, please see: http://lasagne.readthedocs.org/en/latest/modules/objectives.html\n",
      "  obj = objective(output_layer, **objective_params)\n"
     ]
    }
   ],
   "source": [
    "net.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
